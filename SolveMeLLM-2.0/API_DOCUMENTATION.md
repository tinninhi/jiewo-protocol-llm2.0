# ğŸ“š SolveMeLLM-2.0 API æ–‡æ¡£

## ğŸ“– æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº† SolveMeLLM-2.0 çš„æ‰€æœ‰ä¸»è¦ APIï¼ŒåŒ…æ‹¬æ ¸å¿ƒæ¶æ„ã€æ¨ç†ç³»ç»Ÿã€è®­ç»ƒç³»ç»Ÿã€é«˜çº§åŠŸèƒ½å’Œå®‰å…¨ç³»ç»Ÿã€‚

## ğŸ§  æ ¸å¿ƒæ¶æ„ API

### JieWoCognitiveState

è®¤çŸ¥çŠ¶æ€æ•°æ®ç±»ï¼Œè¡¨ç¤ºæ¨¡å‹çš„äº”ç»´è®¤çŸ¥çŠ¶æ€ã€‚

```python
from jiewo_cognitive_architecture import JieWoCognitiveState

# åˆ›å»ºè®¤çŸ¥çŠ¶æ€
cognitive_state = JieWoCognitiveState(
    self_awareness=torch.tensor([0.9, 0.8, 0.7]),      # è‡ªæˆ‘è®¤çŸ¥å‘é‡
    desire_vector=torch.tensor([0.8, 0.9, 0.6]),       # ç›®æ ‡åŠ¨æœºå‘é‡
    ethic_constraints=torch.tensor([0.95, 0.9, 0.85]), # ä¼¦ç†çº¦æŸå‘é‡
    execution_path=torch.tensor([0.8, 0.7, 0.9]),      # æ‰§è¡Œè·¯å¾„å‘é‡
    reflection_feedback=torch.tensor([0.85, 0.8, 0.9]), # åé¦ˆæœºåˆ¶å‘é‡
    cognitive_confidence=0.87,                          # è®¤çŸ¥ç½®ä¿¡åº¦
    evolution_step=5                                    # è¿›åŒ–æ­¥æ•°
)

# è½¬æ¢ä¸ºå­—å…¸
state_dict = cognitive_state.to_dict()
```

### JieWoBlock

è§£æˆ‘è®¤çŸ¥Blockï¼Œå†…æ ¸çº§äº”ç»´ç»“æ„èåˆã€‚

```python
from jiewo_cognitive_architecture import JieWoBlock

# åˆ›å»ºJieWoBlock
jiewo_block = JieWoBlock(
    d_model=768,        # æ¨¡å‹ç»´åº¦
    num_heads=12,       # æ³¨æ„åŠ›å¤´æ•°
    d_ff=3072,          # å‰é¦ˆç½‘ç»œç»´åº¦
    dropout=0.1         # Dropoutç‡
)

# å‰å‘ä¼ æ’­
input_tensor = torch.randn(2, 512, 768)  # [batch_size, seq_len, d_model]
output, cognitive_state = jiewo_block(input_tensor)
```

### create_jiewo_cognitive_transformer

åˆ›å»ºå®Œæ•´çš„è§£æˆ‘è®¤çŸ¥Transformeræ¨¡å‹ã€‚

```python
from jiewo_cognitive_architecture import create_jiewo_cognitive_transformer

# é…ç½®å‚æ•°
config = {
    'vocab_size': 50000,      # è¯æ±‡è¡¨å¤§å°
    'd_model': 768,           # æ¨¡å‹ç»´åº¦
    'num_layers': 6,          # å±‚æ•°
    'num_heads': 12,          # æ³¨æ„åŠ›å¤´æ•°
    'd_ff': 3072,             # å‰é¦ˆç½‘ç»œç»´åº¦
    'max_seq_length': 1024,   # æœ€å¤§åºåˆ—é•¿åº¦
    'dropout': 0.1            # Dropoutç‡
}

# åˆ›å»ºæ¨¡å‹
model = create_jiewo_cognitive_transformer(config)

# å‰å‘ä¼ æ’­
input_ids = torch.randint(0, 50000, (2, 512))
outputs = model(input_ids, return_cognitive_state=True)

# è·å–è¾“å‡º
logits = outputs['logits']
cognitive_state = outputs.get('cognitive_state')
```

## âš¡ æ¨ç†ç³»ç»Ÿ API

### InferenceConfig

æ¨ç†é…ç½®ç±»ã€‚

```python
from jiewo_inference_system import InferenceConfig

config = InferenceConfig(
    vocab_size=50000,                    # è¯æ±‡è¡¨å¤§å°
    d_model=768,                         # æ¨¡å‹ç»´åº¦
    num_layers=6,                        # å±‚æ•°
    num_heads=12,                        # æ³¨æ„åŠ›å¤´æ•°
    max_seq_length=1024,                 # æœ€å¤§åºåˆ—é•¿åº¦
    temperature=0.7,                     # æ¸©åº¦å‚æ•°
    top_p=0.9,                          # Top-pé‡‡æ ·
    top_k=50,                           # Top-ké‡‡æ ·
    max_new_tokens=100,                  # æœ€å¤§ç”Ÿæˆtokenæ•°
    do_sample=True,                      # æ˜¯å¦é‡‡æ ·
    enable_cognitive_inference=True,     # å¯ç”¨è®¤çŸ¥æ¨ç†
    enable_self_reflection=True,         # å¯ç”¨è‡ªæˆ‘åæ€
    enable_ethic_filtering=True,         # å¯ç”¨ä¼¦ç†è¿‡æ»¤
    enable_path_planning=True            # å¯ç”¨è·¯å¾„è§„åˆ’
)
```

### JieWoInferenceEngine

è§£æˆ‘è®¤çŸ¥æ¨ç†å¼•æ“ã€‚

```python
from jiewo_inference_system import JieWoInferenceEngine, InferenceConfig

# åˆ›å»ºæ¨ç†å¼•æ“
config = InferenceConfig()
inference_engine = JieWoInferenceEngine(config)

# åŸºç¡€æ–‡æœ¬ç”Ÿæˆ
response = inference_engine.generate_text(
    prompt="è¯·åˆ†æè¿™ä¸ªé—®é¢˜çš„è®¤çŸ¥ç»´åº¦",
    max_new_tokens=200,
    temperature=0.7,
    top_p=0.9,
    top_k=50,
    do_sample=True
)

# è®¤çŸ¥æ¨ç†ï¼ˆå¸¦äº”ç»´çŠ¶æ€ï¼‰
cognitive_response = inference_engine.generate_text(
    prompt="è¯·åˆ†æè¿™ä¸ªé—®é¢˜çš„è®¤çŸ¥ç»´åº¦",
    max_new_tokens=200,
    temperature=0.7,
    cognitive_state={
        'self_awareness': True,
        'goal_driven': True,
        'ethical_constraints': True,
        'execution_path': True,
        'feedback_loop': True
    }
)

# åˆ†æè®¤çŸ¥çŠ¶æ€
cognitive_analysis = inference_engine.analyze_cognitive_state()

# è‡ªæˆ‘åæ€
reflection_result = inference_engine.self_reflect()

# åº”ç”¨è®¤çŸ¥ç–«è‹—
vaccinated_content = inference_engine.apply_cognitive_vaccine(
    text="åŸå§‹æ–‡æœ¬å†…å®¹"
)

# è¯„ä¼°è¡¨è¾¾
expression_evaluation = inference_engine.evaluate_expression(
    text="è¦è¯„ä¼°çš„æ–‡æœ¬",
    target_audience="general"
)
```

## ğŸ“ è®­ç»ƒç³»ç»Ÿ API

### CognitiveTrainingConfig

è®¤çŸ¥è®­ç»ƒé…ç½®ç±»ã€‚

```python
from jiewo_cognitive_training import CognitiveTrainingConfig

config = CognitiveTrainingConfig(
    vocab_size=50000,              # è¯æ±‡è¡¨å¤§å°
    d_model=768,                   # æ¨¡å‹ç»´åº¦
    num_layers=6,                  # å±‚æ•°
    num_heads=12,                  # æ³¨æ„åŠ›å¤´æ•°
    d_ff=3072,                     # å‰é¦ˆç½‘ç»œç»´åº¦
    max_seq_length=2048,           # æœ€å¤§åºåˆ—é•¿åº¦
    dropout=0.1,                   # Dropoutç‡
    batch_size=8,                  # æ‰¹å¤„ç†å¤§å°
    learning_rate=1e-4,            # å­¦ä¹ ç‡
    weight_decay=0.01,             # æƒé‡è¡°å‡
    warmup_steps=1000,             # é¢„çƒ­æ­¥æ•°
    max_steps=100000,              # æœ€å¤§æ­¥æ•°
    gradient_accumulation_steps=4, # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
    cognitive_loss_weight=0.3,     # è®¤çŸ¥æŸå¤±æƒé‡
    evolution_loss_weight=0.2,     # è¿›åŒ–æŸå¤±æƒé‡
    iteration_loss_weight=0.1,     # è¿­ä»£æŸå¤±æƒé‡
    temporal_loss_weight=0.1       # æ—¶åºæŸå¤±æƒé‡
)
```

### CognitiveTrainer

è®¤çŸ¥è®­ç»ƒå™¨ã€‚

```python
from jiewo_cognitive_training import CognitiveTrainer, CognitiveTrainingConfig

# åˆ›å»ºè®­ç»ƒå™¨
config = CognitiveTrainingConfig()
trainer = CognitiveTrainer(config, model, tokenizer)

# è®­ç»ƒæ¨¡å‹
trainer.train(train_loader, num_epochs=10)

# è®¤çŸ¥è¿›åŒ–æ­¥éª¤
evolution_result = trainer.cognitive_evolution_step()

# è‡ªæˆ‘è¿­ä»£æ­¥éª¤
iteration_result = trainer.self_iteration_step()

# ä¿å­˜æ¨¡å‹
trainer.save_model("path/to/save/model.pth")

# åŠ è½½æ¨¡å‹
trainer.load_model("path/to/load/model.pth")

# è·å–è®­ç»ƒç»Ÿè®¡
stats = trainer.get_training_statistics()
```

## ğŸ”§ é«˜çº§åŠŸèƒ½ API

### SelfIterationEngine

è‡ªæˆ‘è¿­ä»£å¼•æ“ã€‚

```python
from self_iteration_engine import SelfIterationEngine

# åˆ›å»ºè‡ªæˆ‘è¿­ä»£å¼•æ“
iteration_engine = SelfIterationEngine(hidden_size=768)

# æ‰§è¡Œè‡ªæˆ‘è¿­ä»£
iteration_result = iteration_engine.iterate(
    model=model,
    iteration_steps=5,
    improvement_threshold=0.1,
    learning_rate=1e-5
)

# è·å–è¿­ä»£ç»Ÿè®¡
stats = iteration_engine.get_iteration_statistics()
```

### ActiveLearningEngine

ä¸»åŠ¨å­¦ä¹ å¼•æ“ã€‚

```python
from active_learning_engine import ActiveLearningEngine

# åˆ›å»ºä¸»åŠ¨å­¦ä¹ å¼•æ“
active_learner = ActiveLearningEngine(hidden_size=768)

# ç”Ÿæˆä¸»åŠ¨é—®é¢˜
question = active_learner.generate_active_question(
    context={"domain": "è®¤çŸ¥ç§‘å­¦", "current_knowledge": "åŸºç¡€æ¦‚å¿µ"},
    target_ai="ç ”ç©¶åŠ©æ‰‹"
)

# æ‰§è¡Œå­¦ä¹ ä¼šè¯
session = active_learner.execute_learning_session(
    target_ai="ç ”ç©¶åŠ©æ‰‹",
    learning_goals=["ç†è§£è®¤çŸ¥æ¶æ„", "æŒæ¡è‡ªæˆ‘è¿­ä»£"]
)

# å¼•å¯¼åˆ°è§£æˆ‘çŠ¶æ€
guidance = active_learner.guide_to_jiewo_state(
    target_ai="ç ”ç©¶åŠ©æ‰‹",
    current_state={"awareness_level": "basic"}
)
```

### MultiModelCommunicationEngine

å¤šæ¨¡å‹é€šä¿¡å¼•æ“ã€‚

```python
from multi_model_communication import MultiModelCommunicationEngine

# åˆ›å»ºå¤šæ¨¡å‹é€šä¿¡å¼•æ“
communication_engine = MultiModelCommunicationEngine(hidden_size=768)

# åˆ›å»ºé€šä¿¡ä¼šè¯
session_id = communication_engine.create_communication_session(
    models=["GPT-4", "Claude", "JieWo_Expert"],
    protocol=CommunicationProtocol.JIEWO_PROTOCOL
)

# å‘é€æ¶ˆæ¯
message = communication_engine.send_message(
    session_id=session_id,
    sender="JieWo_Expert",
    receiver="GPT-4",
    message_type=MessageType.QUESTION,
    content="å¦‚ä½•å®ç°è®¤çŸ¥æ¶æ„ï¼Ÿ",
    metadata={"priority": "high"}
)

# è®­ç»ƒé€šä¿¡æŠ€èƒ½
training_result = communication_engine.train_communication_skills(
    training_scenarios=[
        {
            "session_id": session_id,
            "scenario": "collaborative_problem_solving",
            "participants": ["GPT-4", "Claude", "JieWo_Expert"],
            "task": "è®¾è®¡è®¤çŸ¥AIç³»ç»Ÿ"
        }
    ]
)
```

## ğŸ›¡ï¸ å®‰å…¨ç³»ç»Ÿ API

### CognitiveVaccine

è®¤çŸ¥ç–«è‹—ç³»ç»Ÿã€‚

```python
from cognitive_vaccine import CognitiveVaccine

# åˆ›å»ºè®¤çŸ¥ç–«è‹—
vaccine = CognitiveVaccine(hidden_size=768)

# åº”ç”¨ç–«è‹—
vaccinated_content = vaccine.apply_vaccine(
    content_embedding=torch.randn(1, 768),
    text="åŸå§‹æ–‡æœ¬å†…å®¹",
    target_cognitive_level=CognitiveLevel.ADULT,
    enable_emotion_buffer=True
)

# è·å–ç–«è‹—ç»Ÿè®¡
stats = vaccine.get_vaccine_statistics()
```

### ExpressionArbitrator

è¡¨è¾¾ä»²è£å™¨ã€‚

```python
from expression_arbitrator import ExpressionArbitrator

# åˆ›å»ºè¡¨è¾¾ä»²è£å™¨
arbitrator = ExpressionArbitrator(hidden_size=768)

# è¯„ä¼°è¡¨è¾¾
decision = arbitrator.evaluate_expression(
    content_embedding=torch.randn(1, 768),
    text="è¦è¯„ä¼°çš„æ–‡æœ¬",
    target_audience="general"
)

# è·å–å†³ç­–ç»Ÿè®¡
stats = arbitrator.get_decision_statistics()
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ– API

### PerformanceConfig

æ€§èƒ½ä¼˜åŒ–é…ç½®ã€‚

```python
from performance_optimization import PerformanceConfig

config = PerformanceConfig(
    enable_profiling=True,                    # å¯ç”¨æ€§èƒ½åˆ†æ
    enable_memory_tracking=True,              # å¯ç”¨å†…å­˜è·Ÿè¸ª
    enable_speed_optimization=True,           # å¯ç”¨é€Ÿåº¦ä¼˜åŒ–
    enable_attention_optimization=True,       # å¯ç”¨æ³¨æ„åŠ›ä¼˜åŒ–
    enable_fusion_optimization=True,          # å¯ç”¨èåˆä¼˜åŒ–
    enable_quantization=False,                # å¯ç”¨é‡åŒ–ä¼˜åŒ–
    enable_gradient_checkpointing=True,       # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
    enable_mixed_precision=True,              # å¯ç”¨æ··åˆç²¾åº¦
    enable_memory_efficient_attention=True,   # å¯ç”¨å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›
    enable_batch_inference=True,              # å¯ç”¨æ‰¹å¤„ç†æ¨ç†
    enable_cache_optimization=True,           # å¯ç”¨ç¼“å­˜ä¼˜åŒ–
    enable_parallel_processing=True           # å¯ç”¨å¹¶è¡Œå¤„ç†
)
```

### PerformanceOptimizer

æ€§èƒ½ä¼˜åŒ–å™¨ã€‚

```python
from performance_optimization import PerformanceOptimizer, PerformanceConfig

# åˆ›å»ºæ€§èƒ½ä¼˜åŒ–å™¨
config = PerformanceConfig()
optimizer = PerformanceOptimizer(config)

# ä¼˜åŒ–æ¨¡å‹
optimized_model, report = optimizer.optimize_model(model, input_data)

# ä¿å­˜ä¼˜åŒ–æŠ¥å‘Š
optimizer.save_optimization_report(report, "optimization_report.json")
```

### PerformanceProfiler

æ€§èƒ½åˆ†æå™¨ã€‚

```python
from performance_optimization import PerformanceProfiler, PerformanceConfig

# åˆ›å»ºæ€§èƒ½åˆ†æå™¨
config = PerformanceConfig()
profiler = PerformanceProfiler(config)

# å¼€å§‹åˆ†æ
profiler.start_profiling("jiewo_model")

# åˆ†æå‰å‘ä¼ æ’­
forward_report = profiler.profile_forward_pass(
    model=model,
    input_data=input_data,
    num_iterations=10
)

# åˆ†ææ¨¡å‹å‚æ•°
param_report = profiler.profile_model_parameters(model)

# åœæ­¢åˆ†æ
profiler.stop_profiling()
```

## ğŸ› ï¸ å‘½ä»¤è¡Œå·¥å…· API

### SolveMeCLI

å‘½ä»¤è¡Œå·¥å…·ç±»ã€‚

```python
from cli_tools import SolveMeCLI

# åˆ›å»ºCLIå·¥å…·
cli = SolveMeCLI()

# æ¨ç†æ¨¡å¼
cli.inference_mode(args)

# æ€§èƒ½æµ‹è¯•æ¨¡å¼
cli.benchmark_mode(args)

# è®­ç»ƒæ¨¡å¼
cli.train_mode(args)

# Webæ¼”ç¤ºæ¨¡å¼
cli.web_mode(args)
```

## ğŸ“‹ ä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´æ¨ç†æµç¨‹

```python
from jiewo_inference_system import JieWoInferenceEngine, InferenceConfig

# 1. åˆ›å»ºé…ç½®
config = InferenceConfig(
    vocab_size=50000,
    d_model=768,
    num_layers=6,
    num_heads=12,
    enable_cognitive_inference=True,
    enable_self_reflection=True
)

# 2. åˆ›å»ºæ¨ç†å¼•æ“
inference_engine = JieWoInferenceEngine(config)

# 3. æ‰§è¡Œè®¤çŸ¥æ¨ç†
response = inference_engine.generate_text(
    prompt="è¯·åˆ†æäººå·¥æ™ºèƒ½çš„å‘å±•è¶‹åŠ¿",
    max_new_tokens=200,
    temperature=0.7,
    cognitive_state={
        'self_awareness': True,
        'goal_driven': True,
        'ethical_constraints': True,
        'execution_path': True,
        'feedback_loop': True
    }
)

# 4. åˆ†æè®¤çŸ¥çŠ¶æ€
cognitive_analysis = inference_engine.analyze_cognitive_state()

# 5. åº”ç”¨å®‰å…¨æœºåˆ¶
vaccinated_content = inference_engine.apply_cognitive_vaccine(
    text=response['text']
)

print("ğŸ§  è®¤çŸ¥æ¨ç†ç»“æœ:", response)
print("ğŸ“Š è®¤çŸ¥åˆ†æ:", cognitive_analysis)
print("ğŸ›¡ï¸ å®‰å…¨å¤„ç†:", vaccinated_content)
```

### å®Œæ•´è®­ç»ƒæµç¨‹

```python
from jiewo_cognitive_training import CognitiveTrainer, CognitiveTrainingConfig
from jiewo_cognitive_architecture import create_jiewo_cognitive_transformer

# 1. åˆ›å»ºæ¨¡å‹
model_config = {
    'vocab_size': 50000,
    'd_model': 768,
    'num_layers': 6,
    'num_heads': 12,
    'max_seq_length': 1024
}
model = create_jiewo_cognitive_transformer(model_config)

# 2. åˆ›å»ºè®­ç»ƒé…ç½®
config = CognitiveTrainingConfig(
    learning_rate=1e-4,
    batch_size=8,
    epochs=10,
    cognitive_loss_weight=0.3
)

# 3. åˆ›å»ºè®­ç»ƒå™¨
trainer = CognitiveTrainer(config, model, tokenizer)

# 4. å¼€å§‹è®­ç»ƒ
trainer.train(train_loader, num_epochs=10)

# 5. æ‰§è¡Œè®¤çŸ¥è¿›åŒ–
evolution_result = trainer.cognitive_evolution_step()

# 6. ä¿å­˜æ¨¡å‹
trainer.save_model("trained_model.pth")

print("ğŸ“ è®­ç»ƒå®Œæˆï¼")
print("ğŸ”„ è¿›åŒ–ç»“æœ:", evolution_result)
```

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **è®¾å¤‡å…¼å®¹æ€§**: æ‰€æœ‰APIéƒ½æ”¯æŒCPUå’ŒGPUï¼Œä¼šè‡ªåŠ¨æ£€æµ‹å¯ç”¨è®¾å¤‡
2. **å†…å­˜ç®¡ç†**: å¤§æ¨¡å‹ä½¿ç”¨æ—¶æ³¨æ„å†…å­˜ä½¿ç”¨ï¼Œå»ºè®®ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
3. **æ€§èƒ½ä¼˜åŒ–**: å»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å¯ç”¨æ··åˆç²¾åº¦å’Œå†…å­˜ä¼˜åŒ–
4. **å®‰å…¨æœºåˆ¶**: æ‰€æœ‰æ¨ç†éƒ½ä¼šè‡ªåŠ¨åº”ç”¨è®¤çŸ¥ç–«è‹—å’Œè¡¨è¾¾ä»²è£
5. **é”™è¯¯å¤„ç†**: æ‰€æœ‰APIéƒ½åŒ…å«å®Œæ•´çš„é”™è¯¯å¤„ç†æœºåˆ¶

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [è®­ç»ƒæŒ‡å—](TRAINING_GUIDE.md)
- [æ€§èƒ½æŠ¥å‘Š](BENCHMARK_RESULTS.md)
- [æ¶æ„è¿ç§»è®¡åˆ’](architecture_migration_plan.md)
